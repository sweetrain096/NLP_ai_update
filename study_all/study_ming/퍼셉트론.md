# 20190909

### 인공지능과 머신러닝

* `인공지능` : 뇌를 흉내내는 인공 신경망과 다양한 머신 러닝 알고리즘을 통해 구현
* `머신 러닝` : 기계 스스로 대량의 데이터로부터 지식이나 패턴을 찾아내서 학습하는 것, 주어진 데이터를 바탕으로 새로운 질문에 대해 예측하는 것이 최종 목적
* `딥 러닝` : 머신러닝 연구의 한 부분으로 인공신경망 분야의 새로운 방식



#### 지도학습

* 컴퓨터에 학습을 시킬 때 사람이 개입하여 정답을 달아주는 방식으로 학습을 진행
* 분류, 회귀

#### 비지도학습

* 사람의 개입 없이 컴퓨터 스스로가 라벨링 되어 있지 않은 데이터에 대해 학습을 하는 방식
* 군집화, 분포 추정

#### 강화학습

* 기계 혹은 컴퓨터로 하여금 현재 상태에서 어떤 행동을 취하는 것이 최적의 것인가를 학습
* 하나의 행동을 취할 때마다 외부에서 보상이 주어지며 이 보상이 최대화 하는 방향으로 학습 진행



#### 머신러닝을 구현하기 위한 알고리즘

* 경사 하강법
* 회귀 기법
  * 선형 회귀
  * 로지스틱 회귀
* 확률 기반
  * 나이브 베이즈 분류기
  * 은닉 마르코프 모델
* 기하 기반
  * k-Means Clustering(kMC)
  * k-Nearest Neighbors(kNN)
  * Support Vector Machine(SVM)
* 인공 신경망
  * Perceptron
  * Multi Layer Perceptron(MLP)
  * Deep Neural Network



## [퍼셉트론](<https://blog.naver.com/samsjang/220948258166>)

* 여러개의 입력 신호가 가지돌기에 도착하면 신경세포 내에서 이들을 하나의 신호로 통합
* 통합된 신호 값이 어떤 임계값을 초과하면 하나의 단일 신호가 생성
* 이 신호가 축삭돌기를 통해 다른 신경세포로 전달
* `MCP뉴런` : 이렇게 단순화 된 원리로 동작하는 뇌세포
* `퍼셉트론 학습 규칙` : 하나의 MCP 뉴런이 출력 신호를 발생할지 안할지 결정하기 위해 MCP 뉴런으로 들어오는 각 입력값에 곱해지는 가중치 값을 자동적으로 학습하는 알고리즘
* 머신러닝의 지도학습이나 분류의 맥락에서 볼 때 하나의 샘플이 어떤 클래스에 속해있는지 예측하는데 사용

![퍼셉1](assets/퍼셉1.png)

* 입력값은 보통 분류를 위한 데이터의 특성을 나타내는 값으로 이루어져 있으며 이 특성값(x0~nx)에 가중치(w0~wn)을 곱한 값을 모두 더해서 하나의 값으로 만듬 -> 순입력 함수(net input function)
* 순입력 함수의 결과값을 특정 임계값과 비교, 순입력 함수 결과값이 이 임계값보다 크면 1, 그렇지 않으면 -1 출력 -> 활성함수(Activaion function)

* 퍼셉트론은 다수의 트레이닝 데이터를 이용하여 일종의 지도 학습을 수행하는 알고리즘
* 트레이닝 데이터 : 데이터의 특성값에 대응되는 실제 결과값
* 입력되는 특성값 x0~xn에 대한 실제 결과값을 y라고 하면 y를 활성 함수에 의해 -1또는 1로 변환
* 변환한 값과 퍼셉트론 알고리즘에 의해 예측된 값이 다르면 같아질 때까지 특정식에 의해 가중치 w0~wn 업데이트 

### 퍼셉트론 구현하기

[출처](<https://excelsior-cjh.tistory.com/169?category=940400>)

1. AND gate

```python
import numpy as np
def AND_basic(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1

inputs = [(0, 0), (1, 0), (0, 1), (1, 1)]
for x1, x2 in inputs:
    y = AND_basic(x1, x2)
    print('({x1}, {x2}) -> {y}'.format(x1=x1, x2=x2, y=y))
```

```
(0, 0) -> 0
(1, 0) -> 0
(0, 1) -> 0
(1, 1) -> 1
```

2. 가중치와 편향 도입

```python
def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1

inputs = [(0, 0), (1, 0), (0, 1), (1, 1)]
for x1, x2 in inputs:
    y = AND(x1, x2)
    print('({x1}, {x2}) -> {y}'.format(x1=x1, x2=x2, y=y))
```

```
(0, 0) -> 0
(1, 0) -> 0
(0, 1) -> 0
(1, 1) -> 1
```

3. NAND게이트와 OR게이트

```python
# NAND
def NAND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([-0.5, -0.5])
    b = 0.7
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1

# OR
def OR(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.2
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1

inputs = [(0, 0), (1, 0), (0, 1), (1, 1)]

print('NAND :')
for x1, x2 in inputs:
    y = NAND(x1, x2)
    print('({x1}, {x2}) -> {y}'.format(x1=x1, x2=x2, y=y))
    
print('OR :')
for x1, x2 in inputs:
    y = OR(x1, x2)
    print('({x1}, {x2}) -> {y}'.format(x1=x1, x2=x2, y=y))
```

```
NAND :
(0, 0) -> 1
(1, 0) -> 1
(0, 1) -> 1
(1, 1) -> 0
OR :
(0, 0) -> 0
(1, 0) -> 1
(0, 1) -> 1
(1, 1) -> 1
```

